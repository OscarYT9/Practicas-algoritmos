Óscar Vilela Rodríguez y Ainhoa de Diego Silva 
oscar.vilela.rodriguez@udc.es; ainhoa.dediego.silva@udc.es 

INTRODUCCIÓN 

En esta primera práctica analizamos y demostramos de manera empírica la fiabilidad, tiempo de ejecución, y complejidad de dos algoritmos propuestos que realizan la suma de la subsecuencia máxima con diferente implementación. Para ello, creamos un programa en Python, compuesto de varios archivos de código: 

Algoritmos.py 
FuncionesTests.py 
FuncionesAuxiliares.py 
Main.py 

ACLARACIONES INICIALES 

Para ejecutar el código debes moverte al directorio y escribir en la terminal python main.py.

Las características de la máquina que usamos se muestran a continuación: 

Nombre del modelo: Lenovo Legion 5 15ITH6H Intel Core i7-11800H/32GB/1TB SSD/RTX3070/15.6" 
Procesador Intel Core i7-11800H (8C / 16T, 2.3 / 4.6GHz, 24MB) 
Memoria RAM 2x 16GB SO-DIMM DDR4-3200 
Almacenamiento 1TB SSD M.2 2280 PCIe 3.0x4 NVMe 


*Este programa en específico se ejecutó en el procesador (CPU) por lo que la tarjeta gráfica (GPU) no es necesaria para su ejecución. 
*Todas las medidas de tiempo han sido tomadas en nanosegundos (ns), mediante la función 	time.perf_counter_ns() , y mostradas por pantalla a su vez en nanosegundos. 
*Todas las funciones aquí comentadas están descritas en mayor profundidad en el código. 

 

Una vez aclaradas las cuestiones básicas, explicaremos paso a paso, el proceso que nos llevó a las conclusiones finales de este informe.

 
DESARRROLLO DE LAS PRUEBAS

1º Creamos el archivo Algoritmos.py en el que definimos las funciones de los algoritmos a comprobar. 

Este código está compuesto por los dos algoritmos a comprobar, cada uno en una función, denominados sumaSubMax1 y sumaSubMax2. Estos resuelven el problema de la suma de la subsecuencia máxima, iterando cada elemento del vector o lista recibido como entrada. 

sumaSubMax1(v: list) -> int: 

	El algoritmo recorre el vector v y calcula la suma de todas las subsecuencias posibles. Luego, compara cada suma con la suma máxima encontrada hasta ese momento y actualiza la suma máxima si se encuentra una suma mayor. 

sumaSubMax2(v: list) -> int. 

	El algoritmo recorre el vector v una vez y calcula la suma acumulativa de los elementos. Si en algún punto la suma acumulativa se vuelve negativa, se reinicia a cero. Mientras se recorre 	el arreglo, se lleva un registro de la suma máxima encontrada hasta ese momento. 

 

2º Comprobamos el correcto funcionamiento de los dos algoritmos y la complejidad algorítmica de forma empírica: 

Para ello creamos el archivo FuncionesTests.py, que a su vez utiliza otras funciones definidas en FuncionesAuxiliares.py, donde definimos las funciones “test”: 

test_resultados(lista):

    Nos permite resolver el problema que se plantea con cada algoritmo.


Test 1 (Casos de Prueba):
[-9,  2, -5, -4,  6]     6       6      - True
[ 4,  0,  9,  2,  5]     20      20     - True
[-2, -1, -9, -7, -1]     0       0      - True
[ 9, -2,  1, -7, -8]     9       9      - True
[15, -2, -5, -4, 16]     20      20     - True
[ 7, -5,  6,  7, -7]     15      15     - True

-la primera columna corresponde al vector de entrada.

-la segunda columna corresponde a la solución dada por la función sumaSubMax1. 

-la tercera columna corresponde a la solución dada por la función sumaSubMax2.

- Usamos la cuarta y última columna para comparar los resultados de las funciones que nos devuelve un resultado True.


Realizamos un segundo test con vectores generados de forma aleatoria comprobando que ambos algoritmos devuelven el mismo resultado.

Test 2 (Vectores Aleatorios):
[-7,  1,  9, -6, -4,  1, -4,  9,  0]     10      10     - True
[ 3, -2,  3, -5,  6,  0,  3, -2, -1]     9       9      - True
[-5, -9, -3,  1,  5, -3,  7, -2, -1]     10      10     - True
[ 4,  7, -8,  6,  4,  1,  8, -8,  5]     22      22     - True
[ 4, -8, -1, -5,  4,  2,  6, -1,  9]     20      20     - True
[ 7,  9,  5,  5,  0,  2, -6, -6, -2]     28      28     - True
[-2, -8,  4,  2, -6, -1,  3, -9,  8]     8       8      - True
[ 6, -9,  9,  9, -2, -6,  1, -3,  0]     18      18     - True
[ 0, -4, -8,  0,  1, -1,  4,  6,  5]     15      15     - True

3º Para comprobar el tiempo de ejecución, creamos la función test_tiempo_complejidad(algoritmo, imprimir_solo_tiempo) que calcula el tiempo y nos permite medir la complejidad de manera empírica gracias a las cotas.
Utilizamos un vector de progresión gométrica 2 porque nos ayuda a visualizar hacia qué valor de tiempo tiende el algoritmo.
Los asteriscos en las tablas de datos simbolizan que esos valores están por debajo del umbral de confianza, por lo que utilizamos el método del promedio, ya que el algoritmo no modifica los valores de entrada (en el caso de otros algoritmos quelos modificasen, habría que usar otro método).

Test 4 (Análisis de Complejidad): (Iteración nº 81)
***SumaSubMax1***
                                                   Subestimada    Ajustada    Sobreeestimada
           n                  t(n) (ns)            t(n)/n^1.8       t(n)/n^2     t(n)/n^2.2
         500               8122800.0000            112.605539      32.491200       9.375010
        1000              44007900.0000            175.198606      44.007900      11.054285
        2000             152546000.0000            174.400141      38.136500       8.339401
        4000             518970600.0000            170.386339      32.435662       6.174628
        8000            2032572000.0000            191.639029      31.758937       5.263177


Como podemos comprobar por la tabla de valores, los valores de la cota subestimada tienden al infinito, porque al dividir los valores entre el tiempo de ejecución, la función es demasiado poequeña como para llegar a una constante.
En cuanto a la cota ajustada, tiende hacia una constante 32.
En el caso de la cota subestimada, cuando los tiempos del algoritmo(t(n)) crecen, la cota sobreestimada dividida entre el tiempo de ejecución tiende a 0.

***SumaSubMax2***
                                                   Subestimada   Ajustada     Sobreestimada
           n                  t(n) (ns)            t(n)/n^0.8       t(n)/n^1     t(n)/n^1.2
*        500                 40650.0000            281.763379      81.300000      23.458300 (promedio de 10 repeticiones)
*       1000                 82240.0000            327.403337      82.240000      20.657754 (promedio de 10 repeticiones)
*       2000                165810.0000            379.128753      82.905000      18.129037 (promedio de 10 repeticiones)
*       4000                350480.0000            460.272732      87.620000      16.679816 (promedio de 10 repeticiones)
*       8000                665490.0000            501.960501      83.186250      13.785850 (promedio de 10 repeticiones)
       16000               2367700.0000           1025.724403     147.981250      21.349254
       32000               3030600.0000            754.064744      94.706250      11.894567
       64000               5314300.0000            759.455074      83.035938       9.078834
      128000              10691700.0000            877.563979      83.528906       7.950507
      256000              21414100.0000           1009.503559      83.648828       6.931255

En este caso aumentamos el rango de los valores que toma n. Por tanto, los valores del tiempo de ejecución son más pequeños en contraste a, los de el tiempo de ejecución dividido entre las cotas, que son más grandes. 
Como podemos comprobar por la tabla de valores, los valores de la cota subestimada tienden al infinito más rápidamente.
En cuanto a la cota ajustada, tiende hacia una constante en un rango de valores [82, 84].
En el caso de la cota subestimada, cuando los tiempos del algoritmo(t(n)) crecen, la cota sobreestimada dividida entre el tiempo de ejecución tiende a 0.

Para intentar evitar datos anómalos, ejecutamos el código en un entorno lo más limpio posible, con el menor número de procesos en segundo plano.
Probamos a ejecutar el código iterándolo un número de veces mayor(100 ejecucuiones) pero viendo que los valores anómalos seguían apareciendo, demostrando así que aumentar el número de iteraciones no es la solución óptima para suprimir los datos anómalos.

CONCLUSIONES

Después de comprobar que los algoritmos llevan al mismo resultado para igual valor de entrada, analizamos la complejidad de cada algoritmo para saber cuál es el mas óptimo,es decir, el que utiliza menor tiempo de ejecución para la misma tarea.
Para cada algoritmo creamos varias cotas con el fin de averiguar su complejidad de manera empírica:
- Primer algoritmo. Hallamos las cotas n^1.8, n^2 y n^2.2
- Segundo algoritmo. Hallamos las cotas n^0.8, n^1 y n^1.2.


Deducimos de los resultados obtenidos, que el algoritmo óptimo para resolver el problema de la suma de la subsecuencia máxima es el algoritmo 2, es decir, O(n). Por lo tanto, afirmamos la menor complejidad del algoritmo óptimo.
De los datos obtenidos, comprobamos que el primer algoritmo, al ser cuadrático, tarda mayor tiempo en realizar la tarea en contraste al algoritmo lineal.